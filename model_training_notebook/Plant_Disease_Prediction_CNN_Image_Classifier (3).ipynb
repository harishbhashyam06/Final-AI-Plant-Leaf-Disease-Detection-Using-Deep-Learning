{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8VSns6fO6Pg"
      },
      "source": [
        "**Seeding for reproducibility**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JSu8kpnEHDPB"
      },
      "outputs": [],
      "source": [
        "# Set seeds for reproducibility\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eyqk5_8AO1Kr"
      },
      "source": [
        "**Importing the dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "16dILovOOFy0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gAnTOlEPR8a"
      },
      "source": [
        "**Data Curation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GT4tQUqBs90l"
      },
      "source": [
        "Upload the kaggle.json file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKWvyGVDtALx",
        "outputId": "f565ec66-6b79-4d7f-ce6f-ecb12f388e37"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZM5gnAAVtH0s"
      },
      "outputs": [],
      "source": [
        "kaggle_credentails = json.load(open(\"kaggle.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xWS6H5mPtNa_"
      },
      "outputs": [],
      "source": [
        "# setup Kaggle API key as environment variables\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_credentails[\"username\"]\n",
        "os.environ['KAGGLE_KEY'] = kaggle_credentails[\"key\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypPVDLobtUr5",
        "outputId": "53a70f81-a8ed-4287-f1f5-678b465142d0"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d abdallahalidev/plantvillage-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20t7J2zctdou",
        "outputId": "71e8ea49-eac0-4f1f-b13c-f59595733d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kaggle.json  plantvillage-dataset.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cjVbT1ZItYe2"
      },
      "outputs": [],
      "source": [
        "# Unzip the downloaded dataset\n",
        "with ZipFile(\"plantvillage-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_5Oa9WPtfXr",
        "outputId": "79a1b2c7-ca9c-4a89-febe-17abc7f399d3"
      },
      "outputs": [],
      "source": [
        "print(os.listdir(\"plantvillage dataset\"))\n",
        "\n",
        "\n",
        "print(len(os.listdir(\"plantvillage dataset/segmented\")))\n",
        "print(os.listdir(\"plantvillage dataset/segmented\")[:5])\n",
        "\n",
        "print(len(os.listdir(\"plantvillage dataset/color\")))\n",
        "print(os.listdir(\"plantvillage dataset/color\")[:5])\n",
        "\n",
        "print(len(os.listdir(\"plantvillage dataset/grayscale\")))\n",
        "print(os.listdir(\"plantvillage dataset/grayscale\")[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snyC_-2jt0z3"
      },
      "source": [
        "**Number of Classes = 38**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFR52Pk6tp2U",
        "outputId": "4917ce76-17f2-4103-85ca-14d2af84dc06"
      },
      "outputs": [],
      "source": [
        "print(len(os.listdir(\"plantvillage dataset/color/Grape___healthy\")))\n",
        "print(os.listdir(\"plantvillage dataset/color/Grape___healthy\")[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhEi6mbpt4aD"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WlqvsdtBttrh"
      },
      "outputs": [],
      "source": [
        "# Dataset Path\n",
        "base_dir = 'plantvillage dataset/color'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XQxHLLbKt6oF",
        "outputId": "960d3327-8801-4a10-e6c5-f5551337a781"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'\n",
        "\n",
        "# Read the image\n",
        "img = mpimg.imread(image_path)\n",
        "\n",
        "print(img.shape)\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Turn off axis numbers\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVgo1I9sDP6B",
        "outputId": "302d2d4b-6f7c-4ddf-ab9e-a9d6bd738b7e"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'\n",
        "\n",
        "# Read the image\n",
        "img = mpimg.imread(image_path)\n",
        "\n",
        "print(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "w6S1jYo0u5o-"
      },
      "outputs": [],
      "source": [
        "# Image Parameters\n",
        "img_size = 224\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcovy3vxvf31"
      },
      "source": [
        "**Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zoJjajTcvTae"
      },
      "outputs": [],
      "source": [
        "# Image Data Generators\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2  # Use 20% of data for validation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnwsA5IPvWNG",
        "outputId": "be155ed6-aa77-4f28-c202-94fba6ea59bd"
      },
      "outputs": [],
      "source": [
        "# Train Generator\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='training',\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtxNLvmbvYNX",
        "outputId": "a60d0b2a-bba4-4595-d5e1-e9f6978ddbab"
      },
      "outputs": [],
      "source": [
        "# Validation Generator\n",
        "validation_generator = data_gen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    subset='validation',\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fE4vUKMkviT8"
      },
      "source": [
        "**Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VUsvwveevZ-m"
      },
      "outputs": [],
      "source": [
        "# Model Definition\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(2, 2))\n",
        "\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(train_generator.num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9qJo-GSvoIB",
        "outputId": "56ed059c-85f2-4490-8dfc-63e25516d2ea"
      },
      "outputs": [],
      "source": [
        "# model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PKi-ot0xvpC8"
      },
      "outputs": [],
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCBezWyLv1hF"
      },
      "source": [
        "**Model training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSvHhJqevyjE",
        "outputId": "51052757-e403-4ed0-87b0-42ff1ff6451b"
      },
      "outputs": [],
      "source": [
        "# Training the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch\n",
        "    epochs=5,  # Number of epochs\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size  # Validation steps\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjQfNu7QwZjw"
      },
      "source": [
        "**Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9SRLiOMv3qm",
        "outputId": "c5680df7-67df-41c9-84c7-bee0b17b7f0c"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation\n",
        "print(\"Evaluating model...\")\n",
        "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "ZxP07UNywYPj",
        "outputId": "228b5e7e-2a21-4cbb-931f-55708ed0cc34"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIeDSJa5xkpy"
      },
      "source": [
        "**Building a Predictive System**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "0onhRrVkv9-M"
      },
      "outputs": [],
      "source": [
        "# Function to Load and Preprocess the Image using Pillow\n",
        "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
        "    # Load the image\n",
        "    img = Image.open(image_path)\n",
        "    # Resize the image\n",
        "    img = img.resize(target_size)\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = np.array(img)\n",
        "    # Add batch dimension\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    # Scale the image values to [0, 1]\n",
        "    img_array = img_array.astype('float32') / 255.\n",
        "    return img_array\n",
        "\n",
        "# Function to Predict the Class of an Image\n",
        "def predict_image_class(model, image_path, class_indices):\n",
        "    preprocessed_img = load_and_preprocess_image(image_path)\n",
        "    predictions = model.predict(preprocessed_img)\n",
        "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
        "    predicted_class_name = class_indices[predicted_class_index]\n",
        "    return predicted_class_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YZkE2k6gwgOR"
      },
      "outputs": [],
      "source": [
        "# Create a mapping from class indices to class names\n",
        "class_indices = {v: k for k, v in train_generator.class_indices.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dja767dwzFH",
        "outputId": "d0344da3-a583-459c-94dc-d63027b1f4a5"
      },
      "outputs": [],
      "source": [
        "class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "StM3_I3UwjFV"
      },
      "outputs": [],
      "source": [
        "# saving the class names as json file\n",
        "json.dump(class_indices, open('class_indices.json', 'w'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJb9gQGRw2Ln",
        "outputId": "f329cc1c-2945-416a-f42d-174a433ff60c"
      },
      "outputs": [],
      "source": [
        "# Example Usage\n",
        "image_path = '/content/test_apple_black_rot.JPG'\n",
        "#image_path = '/content/test_blueberry_healthy.jpg'\n",
        "#image_path = '/content/test_potato_early_blight.jpg'\n",
        "predicted_class_name = predict_image_class(model, image_path, class_indices)\n",
        "\n",
        "# Output the result\n",
        "print(\"Predicted Class Name:\", predicted_class_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBkknsKMyDbs"
      },
      "source": [
        "**Save the model to Google drive or local**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfoTNemcxjk5"
      },
      "outputs": [],
      "source": [
        "model.save('drive/MyDrive/trained_models/plant_disease_prediction_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8ByAMH6ykbN",
        "outputId": "8836c7a9-6d35-421f-b36c-f6fb50fd5cf7"
      },
      "outputs": [],
      "source": [
        "model.save('plant_disease_prediction_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install Additional Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln01Rmj0L8Hg"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python-headless seaborn tqdm -q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import Robustness Testing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"✓ Robustness testing libraries loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Corruption Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageCorruptions:\n",
        "    \"\"\"Apply realistic corruptions to test images\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_gaussian_noise(img, severity=3):\n",
        "        \"\"\"Add Gaussian noise (sensor noise)\"\"\"\n",
        "        noise_levels = [0.04, 0.08, 0.12, 0.16, 0.20]\n",
        "        std = noise_levels[severity - 1]\n",
        "        noise = np.random.normal(0, std * 255, img.shape)\n",
        "        noisy = np.clip(img + noise, 0, 255)\n",
        "        return noisy.astype(np.uint8)\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_salt_pepper_noise(img, severity=3):\n",
        "        \"\"\"Salt & pepper noise (transmission errors)\"\"\"\n",
        "        amounts = [0.01, 0.02, 0.03, 0.05, 0.08]\n",
        "        amount = amounts[severity - 1]\n",
        "        noisy = np.copy(img)\n",
        "        \n",
        "        # Salt\n",
        "        num_salt = int(amount * img.size * 0.5)\n",
        "        coords = [np.random.randint(0, i - 1, num_salt) for i in img.shape[:2]]\n",
        "        noisy[coords[0], coords[1], :] = 255\n",
        "        \n",
        "        # Pepper\n",
        "        num_pepper = int(amount * img.size * 0.5)\n",
        "        coords = [np.random.randint(0, i - 1, num_pepper) for i in img.shape[:2]]\n",
        "        noisy[coords[0], coords[1], :] = 0\n",
        "        \n",
        "        return noisy\n",
        "    \n",
        "    @staticmethod\n",
        "    def apply_motion_blur(img, severity=3):\n",
        "        \"\"\"Motion blur (camera shake)\"\"\"\n",
        "        kernel_sizes = [3, 5, 7, 9, 11]\n",
        "        size = kernel_sizes[severity - 1]\n",
        "        kernel = np.zeros((size, size))\n",
        "        kernel[int((size-1)/2), :] = np.ones(size)\n",
        "        kernel = kernel / size\n",
        "        blurred = cv2.filter2D(img, -1, kernel)\n",
        "        return blurred\n",
        "    \n",
        "    @staticmethod\n",
        "    def apply_gaussian_blur(img, severity=3):\n",
        "        \"\"\"Gaussian blur (out of focus)\"\"\"\n",
        "        kernel_sizes = [3, 5, 7, 9, 11]\n",
        "        ksize = kernel_sizes[severity - 1]\n",
        "        blurred = cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
        "        return blurred\n",
        "    \n",
        "    @staticmethod\n",
        "    def adjust_brightness(img, severity=3):\n",
        "        \"\"\"Adjust brightness (too dark/bright)\"\"\"\n",
        "        factors = [0.4, 0.6, 0.8, 1.3, 1.6]\n",
        "        factor = factors[severity - 1]\n",
        "        adjusted = np.clip(img * factor, 0, 255)\n",
        "        return adjusted.astype(np.uint8)\n",
        "    \n",
        "    @staticmethod\n",
        "    def adjust_contrast(img, severity=3):\n",
        "        \"\"\"Adjust contrast\"\"\"\n",
        "        factors = [0.5, 0.7, 0.9, 1.3, 1.6]\n",
        "        factor = factors[severity - 1]\n",
        "        mean = img.mean()\n",
        "        adjusted = np.clip((img - mean) * factor + mean, 0, 255)\n",
        "        return adjusted.astype(np.uint8)\n",
        "    \n",
        "    @staticmethod\n",
        "    def apply_fog(img, severity=3):\n",
        "        \"\"\"Simulate fog\"\"\"\n",
        "        fog_levels = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "        fog_strength = fog_levels[severity - 1]\n",
        "        fog = np.ones_like(img) * 200\n",
        "        foggy = cv2.addWeighted(img, 1 - fog_strength, fog.astype(np.uint8), fog_strength, 0)\n",
        "        return foggy\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_shadow(img, severity=3):\n",
        "        \"\"\"Add shadow effect\"\"\"\n",
        "        shadow_strengths = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "        strength = shadow_strengths[severity - 1]\n",
        "        \n",
        "        h, w = img.shape[:2]\n",
        "        shadow_mask = np.zeros((h, w), dtype=np.float32)\n",
        "        \n",
        "        for i in range(h):\n",
        "            shadow_mask[i, :int(w * (1 - i/h))] = 1\n",
        "        \n",
        "        shadow_mask = cv2.GaussianBlur(shadow_mask, (51, 51), 0)\n",
        "        \n",
        "        shadowed = img.copy()\n",
        "        for c in range(3):\n",
        "            shadowed[:, :, c] = np.clip(\n",
        "                img[:, :, c] * (1 - strength * shadow_mask), 0, 255\n",
        "            )\n",
        "        \n",
        "        return shadowed.astype(np.uint8)\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_occlusion(img, severity=3):\n",
        "        \"\"\"Add random occlusions\"\"\"\n",
        "        occlusion_ratios = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
        "        ratio = occlusion_ratios[severity - 1]\n",
        "        \n",
        "        h, w = img.shape[:2]\n",
        "        occluded = img.copy()\n",
        "        \n",
        "        num_occlusions = np.random.randint(2, 5)\n",
        "        for _ in range(num_occlusions):\n",
        "            x1 = np.random.randint(0, w)\n",
        "            y1 = np.random.randint(0, h)\n",
        "            size = int(min(h, w) * ratio)\n",
        "            x2 = min(x1 + size, w)\n",
        "            y2 = min(y1 + size, h)\n",
        "            \n",
        "            color = np.random.randint(20, 80, 3)\n",
        "            occluded[y1:y2, x1:x2] = color\n",
        "        \n",
        "        return occluded\n",
        "\n",
        "print(\"✓ Corruption functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize Sample Corruptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_corruptions(sample_image_path, class_indices):\n",
        "    \"\"\"Visualize all corruption types on a sample image\"\"\"\n",
        "    \n",
        "    # Load sample image\n",
        "    from PIL import Image\n",
        "    img = Image.open(sample_image_path)\n",
        "    img = img.resize((224, 224))\n",
        "    img_array = np.array(img)\n",
        "    \n",
        "    corruptions = [\n",
        "        (ImageCorruptions.add_gaussian_noise, 'Gaussian Noise'),\n",
        "        (ImageCorruptions.add_salt_pepper_noise, 'Salt & Pepper'),\n",
        "        (ImageCorruptions.apply_motion_blur, 'Motion Blur'),\n",
        "        (ImageCorruptions.apply_gaussian_blur, 'Gaussian Blur'),\n",
        "        (ImageCorruptions.adjust_brightness, 'Dark'),\n",
        "        (ImageCorruptions.adjust_contrast, 'Low Contrast'),\n",
        "        (ImageCorruptions.apply_fog, 'Fog'),\n",
        "        (ImageCorruptions.add_shadow, 'Shadow'),\n",
        "        (ImageCorruptions.add_occlusion, 'Occlusion'),\n",
        "    ]\n",
        "    \n",
        "    fig, axes = plt.subplots(3, 4, figsize=(15, 12))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    # Original image\n",
        "    axes[0].imshow(img_array)\n",
        "    axes[0].set_title('Original', fontsize=12, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # Corrupted images\n",
        "    for idx, (corrupt_fn, name) in enumerate(corruptions, 1):\n",
        "        corrupted = corrupt_fn(img_array, severity=3)\n",
        "        axes[idx].imshow(corrupted)\n",
        "        axes[idx].set_title(name, fontsize=11)\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    # Hide remaining subplots\n",
        "    for idx in range(len(corruptions) + 1, len(axes)):\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.suptitle('Sample Image Corruptions (Severity=3)', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sample_corruptions.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"✓ Sample corruptions visualized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Robustness Evaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_robustness(model, validation_generator, class_indices, \n",
        "                        severities=[1, 3, 5], max_batches=50):\n",
        "    \"\"\"\n",
        "    Evaluate model robustness on corruptions\n",
        "    \n",
        "    Args:\n",
        "        model: Trained model\n",
        "        validation_generator: Keras ImageDataGenerator\n",
        "        class_indices: Dictionary mapping indices to class names\n",
        "        severities: List of severity levels to test\n",
        "        max_batches: Maximum batches to test (for speed)\n",
        "    \"\"\"\n",
        "    \n",
        "    corruptions = [\n",
        "        (ImageCorruptions.add_gaussian_noise, 'Gaussian Noise'),\n",
        "        (ImageCorruptions.add_salt_pepper_noise, 'Salt & Pepper'),\n",
        "        (ImageCorruptions.apply_motion_blur, 'Motion Blur'),\n",
        "        (ImageCorruptions.apply_gaussian_blur, 'Gaussian Blur'),\n",
        "        (ImageCorruptions.adjust_brightness, 'Brightness'),\n",
        "        (ImageCorruptions.adjust_contrast, 'Contrast'),\n",
        "        (ImageCorruptions.apply_fog, 'Fog'),\n",
        "        (ImageCorruptions.add_shadow, 'Shadow'),\n",
        "        (ImageCorruptions.add_occlusion, 'Occlusion'),\n",
        "    ]\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ROBUSTNESS EVALUATION\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    for corruption_fn, corruption_name in corruptions:\n",
        "        for severity in severities:\n",
        "            print(f\"\\nTesting: {corruption_name} (Severity {severity})\")\n",
        "            \n",
        "            y_true = []\n",
        "            y_pred_clean = []\n",
        "            y_pred_corrupt = []\n",
        "            \n",
        "            # Reset generator\n",
        "            validation_generator.reset()\n",
        "            \n",
        "            for batch_idx in tqdm(range(min(max_batches, len(validation_generator)))):\n",
        "                images, labels = next(validation_generator)\n",
        "                \n",
        "                # Clean predictions\n",
        "                preds_clean = model.predict(images, verbose=0)\n",
        "                y_pred_clean.extend(np.argmax(preds_clean, axis=1))\n",
        "                \n",
        "                # Apply corruption\n",
        "                corrupted_images = []\n",
        "                for img in images:\n",
        "                    img_uint8 = (img * 255).astype(np.uint8)\n",
        "                    corrupted = corruption_fn(img_uint8, severity=severity)\n",
        "                    corrupted_norm = corrupted.astype(np.float32) / 255.0\n",
        "                    corrupted_images.append(corrupted_norm)\n",
        "                \n",
        "                corrupted_batch = np.array(corrupted_images)\n",
        "                \n",
        "                # Corrupted predictions\n",
        "                preds_corrupt = model.predict(corrupted_batch, verbose=0)\n",
        "                y_pred_corrupt.extend(np.argmax(preds_corrupt, axis=1))\n",
        "                \n",
        "                y_true.extend(np.argmax(labels, axis=1))\n",
        "            \n",
        "            # Calculate metrics\n",
        "            acc_clean = accuracy_score(y_true, y_pred_clean)\n",
        "            acc_corrupt = accuracy_score(y_true, y_pred_corrupt)\n",
        "            degradation = acc_clean - acc_corrupt\n",
        "            \n",
        "            result = {\n",
        "                'corruption': corruption_name,\n",
        "                'severity': severity,\n",
        "                'clean_accuracy': float(acc_clean),\n",
        "                'corrupted_accuracy': float(acc_corrupt),\n",
        "                'accuracy_drop': float(degradation),\n",
        "                'relative_drop_%': float((degradation / acc_clean) * 100) if acc_clean > 0 else 0\n",
        "            }\n",
        "            \n",
        "            results.append(result)\n",
        "            \n",
        "            print(f\"  Clean: {acc_clean:.3f} | Corrupt: {acc_corrupt:.3f} | Drop: {degradation:.3f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "print(\"✓ Robustness evaluator defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_robustness_results(results, model_name='Model'):\n",
        "    \"\"\"Create visualizations of robustness results\"\"\"\n",
        "    \n",
        "    df = pd.DataFrame(results)\n",
        "    \n",
        "    # Create output directory\n",
        "    os.makedirs('robustness_results', exist_ok=True)\n",
        "    \n",
        "    # 1. Average accuracy drop by corruption type\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    avg_by_corruption = df.groupby('corruption')['accuracy_drop'].mean().sort_values()\n",
        "    avg_by_corruption.plot(kind='barh', ax=ax, color='coral')\n",
        "    ax.set_xlabel('Average Accuracy Drop', fontsize=12)\n",
        "    ax.set_title(f'{model_name} - Robustness to Corruptions', fontsize=14, fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3, axis='x')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('robustness_results/corruption_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # 2. Accuracy vs Severity\n",
        "    fig, ax = plt.subplots(figsize=(14, 6))\n",
        "    for corruption in df['corruption'].unique():\n",
        "        subset = df[df['corruption'] == corruption]\n",
        "        ax.plot(subset['severity'], subset['corrupted_accuracy'], \n",
        "               marker='o', label=corruption, linewidth=2)\n",
        "    \n",
        "    ax.set_xlabel('Severity Level', fontsize=12)\n",
        "    ax.set_ylabel('Accuracy', fontsize=12)\n",
        "    ax.set_title(f'{model_name} - Accuracy vs Corruption Severity', fontsize=14, fontweight='bold')\n",
        "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('robustness_results/severity_analysis.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    # 3. Heatmap of accuracy drop\n",
        "    pivot = df.pivot(index='corruption', columns='severity', values='accuracy_drop')\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    sns.heatmap(pivot, annot=True, fmt='.3f', cmap='YlOrRd', ax=ax, cbar_kws={'label': 'Accuracy Drop'})\n",
        "    ax.set_title(f'{model_name} - Accuracy Drop Heatmap', fontsize=14, fontweight='bold')\n",
        "    ax.set_xlabel('Severity Level', fontsize=12)\n",
        "    ax.set_ylabel('Corruption Type', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('robustness_results/heatmap.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"✓ Visualizations saved to 'robustness_results/' folder\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_robustness_results(results, model_name='Model'):\n",
        "    \"\"\"Save results to CSV and JSON\"\"\"\n",
        "    \n",
        "    os.makedirs('robustness_results', exist_ok=True)\n",
        "    \n",
        "    df = pd.DataFrame(results)\n",
        "    \n",
        "    # Save CSV\n",
        "    csv_path = f'robustness_results/{model_name}_robustness.csv'\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"✓ CSV saved: {csv_path}\")\n",
        "    \n",
        "    # Save JSON\n",
        "    json_path = f'robustness_results/{model_name}_robustness.json'\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(f\"✓ JSON saved: {json_path}\")\n",
        "    \n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ROBUSTNESS SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\nAverage accuracy drop: {df['accuracy_drop'].mean():.3f} ({df['relative_drop_%'].mean():.1f}%)\")\n",
        "    print(f\"Maximum accuracy drop: {df['accuracy_drop'].max():.3f}\")\n",
        "    print(f\"\\nMost vulnerable corruptions:\")\n",
        "    print(df.groupby('corruption')['accuracy_drop'].mean().sort_values(ascending=False).head())\n",
        "    print(f\"\\nMost robust to:\")\n",
        "    print(df.groupby('corruption')['accuracy_drop'].mean().sort_values().head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RUN ROBUSTNESS EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample corruptions first\n",
        "print(\"Step 1: Visualizing sample corruptions...\")\n",
        "# Pick any test image from your dataset\n",
        "sample_image = '/content/plantvillage dataset/color/Apple___Black_rot/00a914bb-b9e6-4774-ad3c-1b0a30f96b5e___JR_FrgE.S 2993.JPG'\n",
        "visualize_corruptions(sample_image, class_indices)\n",
        "\n",
        "# Run evaluation\n",
        "print(\"\\nStep 2: Running robustness evaluation...\")\n",
        "print(\"This will take 10-20 minutes depending on GPU...\")\n",
        "\n",
        "robustness_results = evaluate_robustness(\n",
        "    model=model,\n",
        "    validation_generator=validation_generator,\n",
        "    class_indices=class_indices,\n",
        "    severities=[1, 3, 5],  # Test mild, moderate, severe\n",
        "    max_batches=50  # Adjust based on time/accuracy tradeoff\n",
        ")\n",
        "\n",
        "# Visualize results\n",
        "print(\"\\nStep 3: Creating visualizations...\")\n",
        "visualize_robustness_results(robustness_results, model_name='CNN_Model')\n",
        "\n",
        "# Save results\n",
        "print(\"\\nStep 4: Saving results...\")\n",
        "save_robustness_results(robustness_results, model_name='CNN_Model')\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ ROBUSTNESS EVALUATION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nCheck the 'robustness_results' folder for:\")\n",
        "print(\"  - CSV file with detailed results\")\n",
        "print(\"  - JSON file for further analysis\")\n",
        "print(\"  - Visualization plots\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare Multiple Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compare_multiple_models(model_paths, model_names, validation_generator, class_indices):\n",
        "    \"\"\"Compare robustness across multiple models\"\"\"\n",
        "    \n",
        "    all_results = {}\n",
        "    \n",
        "    for model_path, model_name in zip(model_paths, model_names):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Evaluating {model_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "        \n",
        "        # Load model\n",
        "        from tensorflow import keras\n",
        "        model = keras.models.load_model(model_path)\n",
        "        \n",
        "        # Evaluate\n",
        "        results = evaluate_robustness(\n",
        "            model=model,\n",
        "            validation_generator=validation_generator,\n",
        "            class_indices=class_indices,\n",
        "            severities=[3],  # Just test moderate severity for comparison\n",
        "            max_batches=50\n",
        "        )\n",
        "        \n",
        "        all_results[model_name] = results\n",
        "    \n",
        "    # Comparative visualization\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    for model_name, results in all_results.items():\n",
        "        df = pd.DataFrame(results)\n",
        "        avg_by_corruption = df.groupby('corruption')['accuracy_drop'].mean()\n",
        "        ax.plot(avg_by_corruption.index, avg_by_corruption.values, \n",
        "               marker='o', label=model_name, linewidth=2)\n",
        "    \n",
        "    ax.set_xlabel('Corruption Type', fontsize=12)\n",
        "    ax.set_ylabel('Average Accuracy Drop', fontsize=12)\n",
        "    ax.set_title('Model Comparison - Robustness to Corruptions', fontsize=14, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('robustness_results/model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n✓ Model comparison complete!\")\n",
        "    \n",
        "    return all_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Metrics & Confusion Matrices – All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")\n",
        "\n",
        "models = {\n",
        "    \"Custom CNN\": custom_cnn_model,\n",
        "    \"VGG16\": vgg16_model,\n",
        "    \"MobileNetV2\": mobilenet_model,\n",
        "    \"DenseNet121\": densenet_model\n",
        "}\n",
        "\n",
        "# True labels and class names\n",
        "y_true = test_generator.classes\n",
        "class_names = list(test_generator.class_indices.keys())\n",
        "\n",
        "cms = {}\n",
        "reports = {}\n",
        "accuracies = {}\n",
        "f1_scores = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Running predictions for: {name} ...\")\n",
        "\n",
        "    y_prob = model.predict(test_generator, verbose=0)\n",
        "    y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cms[name] = cm\n",
        "\n",
        "    # Classification report (dict)\n",
        "    rep = classification_report(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        target_names=class_names,\n",
        "        output_dict=True\n",
        "    )\n",
        "    reports[name] = rep\n",
        "\n",
        "    # Accuracy\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    accuracies[name] = acc\n",
        "\n",
        "    # Weighted F1-score\n",
        "    f1 = rep[\"weighted avg\"][\"f1-score\"]\n",
        "    f1_scores[name] = f1\n",
        "\n",
        "    print(f\"{name}: Accuracy={acc:.4f}, F1={f1:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot confusion matrix for each model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, cm in cms.items():\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=False,\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names\n",
        "    )\n",
        "    plt.title(f\"Confusion Matrix – {name}\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(accuracies.keys(), accuracies.values())\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "\n",
        "for i, v in enumerate(accuracies.values()):\n",
        "    plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "F1-score comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(f1_scores.keys(), f1_scores.values())\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Weighted F1-score\")\n",
        "plt.title(\"Model F1-score Comparison\")\n",
        "\n",
        "for i, v in enumerate(f1_scores.values()):\n",
        "    plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grad-CAM for All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_img_array(img_path, size):\n",
        "    img = image.load_img(img_path, target_size=size)\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = x / 255.0\n",
        "    return x\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # Build grad model\n",
        "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [last_conv_layer.output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "\n",
        "        # Gradient of top predicted class wrt conv layer output\n",
        "        grads = tape.gradient(class_channel, conv_outputs)\n",
        "\n",
        "    # Mean of gradients over (h, w)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.reduce_max(heatmap + 1e-8)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def display_gradcam(img_path, heatmap, alpha=0.4):\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
        "    heatmap_color = cv2.cvtColor(heatmap_color, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    superimposed_img = np.uint8(heatmap_color * alpha + img)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Original\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"Grad-CAM Overlay\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Robustness Tests: Noise, Blur, Brightness, Occlusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = []\n",
        "y_true = []\n",
        "\n",
        "for i in range(len(test_generator)):\n",
        "    x_batch, y_batch = test_generator[i]\n",
        "    X_test.append(x_batch)\n",
        "    y_true.append(np.argmax(y_batch, axis=1))\n",
        "\n",
        "X_test = np.concatenate(X_test, axis=0)\n",
        "y_true = np.concatenate(y_true, axis=0)\n",
        "\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_true shape:\", y_true.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def add_gaussian_noise(images, std=0.1):\n",
        "    noisy = images + np.random.normal(0, std, images.shape)\n",
        "    return np.clip(noisy, 0., 1.)\n",
        "\n",
        "def apply_blur(images, ksize=5):\n",
        "    blurred = []\n",
        "    for img in images:\n",
        "        img_uint8 = (img * 255).astype(np.uint8)\n",
        "        blur = cv2.GaussianBlur(img_uint8, (ksize, ksize), 0)\n",
        "        blurred.append(blur.astype(np.float32) / 255.0)\n",
        "    return np.stack(blurred, axis=0)\n",
        "\n",
        "def adjust_brightness(images, factor=1.5):\n",
        "    bright = images * factor\n",
        "    return np.clip(bright, 0., 1.)\n",
        "\n",
        "def apply_occlusion(images, box_frac=0.3):\n",
        "    occluded = images.copy()\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    box_h, box_w = int(h * box_frac), int(w * box_frac)\n",
        "\n",
        "    for i in range(images.shape[0]):\n",
        "        y = np.random.randint(0, h - box_h)\n",
        "        x = np.random.randint(0, w - box_w)\n",
        "        occluded[i, y:y+box_h, x:x+box_w, :] = 0.0\n",
        "    return occluded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_under_corruption(model, X, y_true, corruption_fn, name):\n",
        "    X_corrupt = corruption_fn(X)\n",
        "    y_prob = model.predict(X_corrupt, verbose=0)\n",
        "    y_pred = np.argmax(y_prob, axis=1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    return acc\n",
        "\n",
        "corruptions = {\n",
        "    \"Gaussian Noise\": lambda x: add_gaussian_noise(x, std=0.1),\n",
        "    \"Blur\": lambda x: apply_blur(x, ksize=7),\n",
        "    \"Brightness\": lambda x: adjust_brightness(x, factor=1.5),\n",
        "    \"Occlusion\": lambda x: apply_occlusion(x, box_frac=0.3),\n",
        "}\n",
        "\n",
        "robustness_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nRobustness – {model_name}\")\n",
        "    baseline_acc = accuracies[model_name]\n",
        "    robustness_results[model_name] = {\"Clean\": baseline_acc}\n",
        "\n",
        "    for corr_name, corr_fn in corruptions.items():\n",
        "        acc = evaluate_under_corruption(model, X_test, y_true, corr_fn, corr_name)\n",
        "        robustness_results[model_name][corr_name] = acc\n",
        "        print(f\"{corr_name}: {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model_name, result in robustness_results.items():\n",
        "    labels = list(result.keys())\n",
        "    values = list(result.values())\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.bar(labels, values)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(f\"Robustness – {model_name}\")\n",
        "    for i, v in enumerate(values):\n",
        "        plt.text(i, v + 0.01, f\"{v:.3f}\", ha=\"center\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
