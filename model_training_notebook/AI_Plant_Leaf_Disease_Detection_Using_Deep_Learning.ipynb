{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "99829a70",
      "metadata": {
        "id": "99829a70"
      },
      "source": [
        "## 0. Setup & Versions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f14c6fc5",
      "metadata": {
        "collapsed": true,
        "id": "f14c6fc5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os, sys, random, math, json, itertools, pathlib, time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('TensorFlow:', tf.__version__)\n",
        "print('GPU Available:', tf.config.list_physical_devices('GPU'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da7e288a",
      "metadata": {
        "id": "da7e288a"
      },
      "source": [
        "## 1. Config (Paths, Hyperparameters, Reproducibility)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bab42b9",
      "metadata": {
        "id": "5bab42b9"
      },
      "outputs": [],
      "source": [
        "DATASET_ROOT = r\"C:\\Users\\haris\\Downloads\\Multi_Crop_Dataset\\dataset\" # <-- Corrected Path\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS_HEAD = 10\n",
        "EPOCHS_FINETUNE = 10\n",
        "FINE_TUNE_AT = 100\n",
        "LEARNING_RATE = 1e-3\n",
        "FINE_TUNE_LR = 1e-4\n",
        "SEED = 42\n",
        "SAVE_DIR = 'trained_models'\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83052527",
      "metadata": {
        "id": "83052527"
      },
      "source": [
        "## 2. Load Datasets (train/val/test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0eeb0c2",
      "metadata": {
        "collapsed": true,
        "id": "a0eeb0c2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "full_train_ds, temp_val_ds = image_dataset_from_directory(\n",
        "    DATASET_ROOT,\n",
        "    validation_split=0.2,\n",
        "    subset=\"both\",\n",
        "    seed=SEED,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds_size = tf.data.experimental.cardinality(temp_val_ds)\n",
        "val_ds = temp_val_ds.take(val_ds_size // 2)\n",
        "test_ds = temp_val_ds.skip(val_ds_size // 2)\n",
        "\n",
        "class_names = full_train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "print(f'Classes found: {class_names}')\n",
        "print(f'Number of classes: {num_classes}')\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = full_train_ds.prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(AUTOTUNE)\n",
        "\n",
        "print(\"\\nSuccessfully created train, validation, and test datasets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ced87a73",
      "metadata": {
        "id": "ced87a73"
      },
      "source": [
        "## 3. Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a483cda",
      "metadata": {
        "id": "4a483cda"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "], name='augmentation')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6c2fefd",
      "metadata": {
        "id": "f6c2fefd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_history(history, title='Training History'):\n",
        "    h = history.history\n",
        "    plt.figure()\n",
        "    plt.plot(h['accuracy'], label='train_acc')\n",
        "    if 'val_accuracy' in h: plt.plot(h['val_accuracy'], label='val_acc')\n",
        "    plt.title(title); plt.xlabel('epoch'); plt.ylabel('accuracy'); plt.legend(); plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(h['loss'], label='train_loss')\n",
        "    if 'val_loss' in h: plt.plot(h['val_loss'], label='val_loss')\n",
        "    plt.title(title); plt.xlabel('epoch'); plt.ylabel('loss'); plt.legend(); plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a68380a2",
      "metadata": {
        "id": "a68380a2"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, dataset, class_names, model_name='model', out_dir='trained_models'):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for images, labels in dataset:\n",
        "        probs = model.predict(images, verbose=0)\n",
        "        y_pred.extend(np.argmax(probs, axis=1).tolist())\n",
        "        y_true.extend(labels.numpy().tolist())\n",
        "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
        "    df_report = pd.DataFrame(report).transpose()\n",
        "    acc = report['accuracy']\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
        "    fig = plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=False, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix: {model_name}'); plt.ylabel('True'); plt.xlabel('Pred')\n",
        "    fig_path = os.path.join(out_dir, f'{model_name}_confusion_matrix.png')\n",
        "    fig.savefig(fig_path, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    csv_path = os.path.join(out_dir, f'{model_name}_classification_report.csv')\n",
        "    df_report.to_csv(csv_path, index=True)\n",
        "\n",
        "    return acc, csv_path, fig_path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39090101",
      "metadata": {
        "id": "39090101"
      },
      "source": [
        "## 4. Model Builders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db5631f4",
      "metadata": {
        "id": "db5631f4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_custom_cnn(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape + (3,))\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "    # 6 conv + 5 pool\n",
        "    for filters in [32, 64, 64, 128, 128, 256]:\n",
        "        x = layers.Conv2D(filters, 3, padding='same', activation='relu')(x)\n",
        "        x = layers.MaxPooling2D()(x)\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(256, activation='relu')(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return keras.Model(inputs, outputs, name='CustomCNN')\n",
        "\n",
        "def build_tl_model(base, input_shape, num_classes, name='TLModel'):\n",
        "    base.trainable = False\n",
        "    inputs = keras.Input(shape=input_shape + (3,))\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1./255)(x)\n",
        "    x = base(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    return keras.Model(inputs, outputs, name=name)\n",
        "\n",
        "def compile_model(model, lr):\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9be035",
      "metadata": {
        "id": "ef9be035"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications import VGG16, MobileNetV2, DenseNet121\n",
        "\n",
        "input_shape = (224, 224)\n",
        "models = {}\n",
        "\n",
        "models['CustomCNN'] = build_custom_cnn(input_shape, num_classes)\n",
        "\n",
        "vgg = VGG16(weights='imagenet', include_top=False, input_shape=input_shape + (3,))\n",
        "models['VGG16'] = build_tl_model(vgg, input_shape, num_classes, name='VGG16_TL')\n",
        "\n",
        "mnet = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape + (3,))\n",
        "models['MobileNetV2'] = build_tl_model(mnet, input_shape, num_classes, name='MobileNetV2_TL')\n",
        "\n",
        "dnet = DenseNet121(weights='imagenet', include_top=False, input_shape=input_shape + (3,))\n",
        "models['DenseNet121'] = build_tl_model(dnet, input_shape, num_classes, name='DenseNet121_TL')\n",
        "\n",
        "for name, m in models.items():\n",
        "    compile_model(m, 1e-3)\n",
        "    print(f\"\\n{name} summary:\")\n",
        "    m.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf2a0822",
      "metadata": {
        "id": "cf2a0822"
      },
      "source": [
        "## 5. Train (Phase 1: Frozen base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a053e0",
      "metadata": {
        "id": "03a053e0"
      },
      "outputs": [],
      "source": [
        "\n",
        "callbacks = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)]\n",
        "histories = {}\n",
        "val_accs_phase1 = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n===== Training {name} (frozen base) =====\")\n",
        "    h = model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks, verbose=1)\n",
        "    histories[name] = h\n",
        "    plot_history(h, title=f'{name} (frozen)')\n",
        "    val_accs_phase1[name] = max(h.history.get('val_accuracy', [0.0]))\n",
        "\n",
        "val_accs_phase1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "462e8261",
      "metadata": {
        "id": "462e8261"
      },
      "source": [
        "## 6. Fine-tune (Unfreeze top layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29393453",
      "metadata": {
        "id": "29393453"
      },
      "outputs": [],
      "source": [
        "\n",
        "def unfreeze_from(model, fine_tune_at=100):\n",
        "    # Try to unfreeze top layers of the base submodel\n",
        "    unfrozen = 0\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, keras.Model):\n",
        "            for i, bl in enumerate(layer.la yers):\n",
        "                bl.trainable = (i >= fine_tune_at)\n",
        "                if bl.trainable: unfrozen += 1\n",
        "    print('Unfrozen layers:', unfrozen)\n",
        "\n",
        "fine_tune_histories = {}\n",
        "val_accs_phase2 = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name != 'CustomCNN':\n",
        "        print(f\"\\n===== Fine-tuning {name} =====\")\n",
        "        unfreeze_from(model, fine_tune_at=100)\n",
        "    else:\n",
        "        print(f\"\\n===== Fine-tuning {name} (already trainable) =====\")\n",
        "    compile_model(model, 1e-4)\n",
        "    h2 = model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=[keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)], verbose=1)\n",
        "    fine_tune_histories[name] = h2\n",
        "    plot_history(h2, title=f'{name} (fine-tune)')\n",
        "    val_accs_phase2[name] = max(h2.history.get('val_accuracy', [0.0]))\n",
        "\n",
        "val_accs_phase2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b650f0",
      "metadata": {
        "id": "68b650f0"
      },
      "source": [
        "## 7. Evaluate on Test & Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67c2298",
      "metadata": {
        "id": "a67c2298"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json, os\n",
        "\n",
        "results = []\n",
        "best_name = None\n",
        "best_val = -1.0\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n===== Test Evaluation: {name} =====\")\n",
        "    test_acc, report_csv, cm_png = evaluate_model(model, test_ds, class_names, model_name=name, out_dir='trained_models')\n",
        "    best_val_acc = max(val_accs_phase2.get(name, 0.0), val_accs_phase1.get(name, 0.0))\n",
        "    if best_val_acc > best_val:\n",
        "        best_val = best_val_acc\n",
        "        best_name = name\n",
        "    model_path = os.path.join('trained_models', f'{name}.h5')\n",
        "    model.save(model_path)\n",
        "    results.append({'name': name, 'val_best': float(best_val_acc), 'test_acc': float(test_acc),\n",
        "                    'report_csv': report_csv, 'confusion_matrix_png': cm_png, 'model_path': model_path})\n",
        "\n",
        "with open(os.path.join('trained_models', 'results.json'), 'w') as f:\n",
        "    json.dump({'results': results, 'best_model': best_name}, f, indent=2)\n",
        "\n",
        "print('\\nSummary:')\n",
        "for r in sorted(results, key=lambda x: x['val_best'], reverse=True):\n",
        "    print(f\"{r['name']}: val_best={r['val_best']:.4f}, test_acc={r['test_acc']:.4f}\")\n",
        "print('Best model (by val):', best_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "881c3f4a",
      "metadata": {
        "id": "881c3f4a"
      },
      "source": [
        "## 8. Quick Inference (single image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e0479a",
      "metadata": {
        "id": "38e0479a"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json, os\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "with open(os.path.join('trained_models', 'results.json'), 'r') as f:\n",
        "    info = json.load(f)\n",
        "best_name = info['best_model']\n",
        "best_model_path = [r['model_path'] for r in info['results'] if r['name'] == best_name][0]\n",
        "best_model = keras.models.load_model(best_model_path)\n",
        "print('Loaded best model:', best_name)\n",
        "\n",
        "def predict_image(img_path, img_size=(224,224)):\n",
        "    img = keras.utils.load_img(img_path, target_size=img_size)\n",
        "    x = keras.utils.img_to_array(img)[None, ...] / 255.0\n",
        "    probs = best_model.predict(x, verbose=0)[0]\n",
        "    idx = int(np.argmax(probs))\n",
        "    return class_names[idx], float(probs[idx])\n",
        "\n",
        "# Example:\n",
        "label, conf = predict_image(r'Downloads/Multi_Crop_Dataset/dataset/tomato/Tomato_Early_blight/0abc57ec-7f3b-482a-8579-21f3b2fb780b___RS_Erly.B 7609.JPG')\n",
        "print(label, conf)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:x86_64]",
      "language": "python",
      "name": "conda-env-x86_64-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

